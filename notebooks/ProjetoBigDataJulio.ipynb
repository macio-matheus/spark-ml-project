{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"projeto\")\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "session = pyspark.sql.SparkSession.builder.config(conf=SparkConf())\n",
    "spark = session.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CODG_LINHA: string (nullable = true)\n",
      " |-- CODG_INSTALACAO_LINHA: string (nullable = true)\n",
      " |-- RAP_CICLO: string (nullable = true)\n",
      " |-- ESTADO: string (nullable = true)\n",
      " |-- EQUIPE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados de linhas de transmissão\n",
    "lt=spark.read.load(\"linhas.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\", encoding=\"iso-8859-1\").\\\n",
    "select('CODG_ATIVO','CODG_INSTALACAO','RAP_CICLO_FUNCAO','ESTADO_ATIVO','EQUIPE_RESPONSAVEL').\\\n",
    "toDF('CODG_LINHA', 'CODG_INSTALACAO_LINHA', 'RAP_CICLO','ESTADO', 'EQUIPE')\n",
    "lt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+---------+------+------+\n",
      "|  CODG_LINHA|CODG_INSTALACAO_LINHA|RAP_CICLO|ESTADO|EQUIPE|\n",
      "+------------+---------------------+---------+------+------+\n",
      "|LTCHE.000001|             ABXMLUR1| 63930,25|     A|  SPML|\n",
      "|LTCHE.000002|             ABXMXTR1| 52127,74|     A|  SPML|\n",
      "|LTCHE.000003|             ABXZBUR1| 53111,28|     A|  SPML|\n",
      "+------------+---------------------+---------+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lt.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CODG_ATIVO: string (nullable = true)\n",
      " |-- CODG_INSTALACAO: string (nullable = true)\n",
      " |-- QTDCIRC: integer (nullable = true)\n",
      " |-- CRITICIDADE: integer (nullable = true)\n",
      " |-- VAO_DE_FRENTE: string (nullable = true)\n",
      " |-- ALTURA_UTIL: string (nullable = true)\n",
      " |-- TRAVESSIA_LT: integer (nullable = true)\n",
      " |-- TRAVESSIA_ESTRADA: integer (nullable = true)\n",
      " |-- POVOAMENTO: integer (nullable = true)\n",
      " |-- VANDALISMO: integer (nullable = true)\n",
      " |-- INVASAO: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando dados de estruturas\n",
    "estr=spark.read.load(\"estruturas.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\", encoding=\"iso-8859-1\").\\\n",
    "select('CODG_ATIVO','CODG_INSTALACAO','QTDCIRC','CRITICIDADE','VAO_DE_FRENTE', 'ALTURA_UTIL','TRAVESSIA_LT','TRAVESSIA_ESTRADA','POVOAMENTO', 'VANDALISMO','INVASAO')\n",
    "estr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------+-----------+-------------+\n",
      "| CODG_ATIVO|CODG_INSTALACAO|QTDCIRC|CRITICIDADE|VAO_DE_FRENTE|\n",
      "+-----------+---------------+-------+-----------+-------------+\n",
      "|ESTR.005494|       JALJALU1|   null|       null|          505|\n",
      "|ESTR.005513|       JALJALU1|   null|       null|          152|\n",
      "|ESTR.005794|       JALJALU1|   null|       null|          430|\n",
      "+-----------+---------------+-------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estr.select('CODG_ATIVO','CODG_INSTALACAO','QTDCIRC','CRITICIDADE','VAO_DE_FRENTE').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazendo join entre os dados\n",
    "join = lt.join(estr, lt.CODG_INSTALACAO_LINHA == estr.CODG_INSTALACAO)\n",
    "\n",
    "# limpando valores ausentes\n",
    "menor_criticidade = join.agg({'CRITICIDADE':'min'}).collect()[0][0]\n",
    "menor_criticidade\n",
    "\n",
    "join = join.fillna({'RAP_CICLO': 0, 'QTDCIRC':0, 'VAO_DE_FRENTE': 0, 'ALTURA_UTIL': 0, 'CRITICIDADE':menor_criticidade})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|RAP_CICLO| RAP_CICLO_NORM|\n",
      "+---------+---------------+\n",
      "| 63930,25|0.0010992653310|\n",
      "| 63930,25|0.0010992653310|\n",
      "| 63930,25|0.0010992653310|\n",
      "+---------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalizando a base \n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import DoubleType, StringType, DecimalType\n",
    "\n",
    "# Criando uma user defined function para fazer replace do ',' pelo '.'\n",
    "udf = UserDefinedFunction(lambda x: x.replace(\",\",\".\"), StringType())\n",
    "\n",
    "join = join.withColumn('RAP_CICLO_NUMBER', udf(join.RAP_CICLO).cast(DecimalType(10,2)))\n",
    "\n",
    "maximaRAP =  join.agg({'RAP_CICLO_NUMBER':'max'}).collect()[0][0]\n",
    "\n",
    "base_dados = join.withColumn('RAP_CICLO_NORM', join.RAP_CICLO_NUMBER/maximaRAP).\\\n",
    "            withColumn('CRITICIDADE_NORM', join.CRITICIDADE/maximaRAP).\\\n",
    "            withColumn('QTDCIRC_NORM', join.QTDCIRC/maximaRAP).\\\n",
    "            withColumn('VAO_DE_FRENTE_NORM', join.VAO_DE_FRENTE.cast(DoubleType())/maximaRAP).\\\n",
    "            withColumn('ALTURA_UTIL_NORM', join.ALTURA_UTIL.cast(DoubleType())/maximaRAP).\\\n",
    "            withColumn('TRAVESSIA_LT_NORM', join.TRAVESSIA_LT/maximaRAP).\\\n",
    "            withColumn('TRAVESSIA_ESTRADA_NORM', join.TRAVESSIA_ESTRADA/maximaRAP).\\\n",
    "            withColumn('POVOAMENTO_NORM', join.POVOAMENTO/maximaRAP).\\\n",
    "            withColumn('VANDALISMO_NORM', join.VANDALISMO/maximaRAP).\\\n",
    "            withColumn('INVASAO_NORM', join.INVASAO/maximaRAP)\n",
    "\n",
    "base_dados.select('RAP_CICLO', 'RAP_CICLO_NORM').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+\n",
      "|  CODG_LINHA| CODG_ATIVO|            features|\n",
      "+------------+-----------+--------------------+\n",
      "|LTCHE.000001|ESTR.000039|(10,[0,1,3,4],[0....|\n",
      "|LTCHE.000001|ESTR.000038|(10,[0,1,3,4],[0....|\n",
      "|LTCHE.000001|ESTR.000037|(10,[0,1,3,4],[0....|\n",
      "+------------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preparação da base para aplicar no modelo\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "base_dados = base_dados.na.fill(0)\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=['RAP_CICLO_NORM','QTDCIRC_NORM','CRITICIDADE_NORM','VAO_DE_FRENTE_NORM','ALTURA_UTIL_NORM','TRAVESSIA_LT_NORM','TRAVESSIA_ESTRADA_NORM','POVOAMENTO_NORM','VANDALISMO_NORM','INVASAO_NORM'], outputCol=\"features\")\n",
    "new_df = vecAssembler.transform(base_dados)\n",
    "new_df.select('CODG_LINHA', 'CODG_ATIVO', 'features').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------+\n",
      "|  CODG_LINHA| CODG_ATIVO|prediction|\n",
      "+------------+-----------+----------+\n",
      "|LTCHE.000001|ESTR.000039|         3|\n",
      "|LTCHE.000001|ESTR.000038|         3|\n",
      "|LTCHE.000001|ESTR.000037|         3|\n",
      "+------------+-----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=5, seed=1)  # 5 clusters here\n",
    "model = kmeans.fit(new_df.select('features'))\n",
    "transformed = model.transform(new_df)\n",
    "transformed.select('CODG_LINHA', 'CODG_ATIVO', 'prediction').show(3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salva resultado num arquivo csv\n",
    "transformed.select('CODG_LINHA', 'CODG_INSTALACAO', 'CODG_ATIVO', 'RAP_CICLO','QTDCIRC','CRITICIDADE','VAO_DE_FRENTE','ALTURA_UTIL','TRAVESSIA_LT','TRAVESSIA_ESTRADA','POVOAMENTO','VANDALISMO','INVASAO', 'prediction').\\\n",
    "            withColumn('QTDCIRC', transformed.QTDCIRC.cast(StringType())).\\\n",
    "            withColumn('CRITICIDADE', transformed.CRITICIDADE.cast(StringType())).\\\n",
    "            withColumn('VAO_DE_FRENTE', transformed.VAO_DE_FRENTE.cast(StringType())).\\\n",
    "            withColumn('ALTURA_UTIL', transformed.ALTURA_UTIL.cast(StringType())).\\\n",
    "            withColumn('TRAVESSIA_LT', transformed.TRAVESSIA_LT.cast(StringType())).\\\n",
    "            withColumn('TRAVESSIA_ESTRADA', transformed.TRAVESSIA_ESTRADA.cast(StringType())).\\\n",
    "            withColumn('POVOAMENTO', transformed.POVOAMENTO.cast(StringType())).\\\n",
    "            withColumn('VANDALISMO', transformed.VANDALISMO.cast(StringType())).\\\n",
    "            withColumn('INVASAO', transformed.INVASAO.cast(StringType())).\\\n",
    "            withColumn('prediction', transformed.prediction.cast(StringType())).\\\n",
    "            write.csv('predictions.csv', header='true', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
